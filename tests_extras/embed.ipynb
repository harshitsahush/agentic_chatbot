{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.10/site-packages (0.2.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.10/site-packages (from langchain) (3.10.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in ./.venv/lib/python3.10/site-packages (from langchain) (0.2.30)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.10/site-packages (from langchain) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (4.44.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_text_splitters in ./.venv/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in ./.venv/lib/python3.10/site-packages (from langchain_text_splitters) (0.2.30)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.10->langchain_text_splitters) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in ./.venv/lib/python3.10/site-packages (3.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
      "Using cached faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install sentence-transformers\n",
    "!pip install langchain_text_splitters\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARSHIT SAHU\\nMachine Learning Engineer\\n+91 6393455797 | harshitsahu.sh@gmail.com | LinkedIn | Github\\nCAREER SUMMARY:\\nAspiring Machine Learning Engineer with a strong foundation in machine learning algorithms and deep\\nlearning, seeking to contribute skills and enthusiasm. Proficient in Python, TensorFlow, and Keras, with\\nacademic projects demonstrating the ability to develop and deploy machine learning models effectively.\\nWebkul\\nMachine Learning Engineer Intern |  01 July, 2024 - Present\\nCreated a RAG chatbot with memory retention using product documentation to help the customers\\nsolve their queries.\\nCreated a resume extractor application to extract the relevant details such as personal info, skillset,\\nyears of experience from a collection of CVs.\\nCreated API using Flask to store the extracted information in a database for future processing.\\nVisual Search\\nBuilt an app using Streamlit to find the images present in a dataset similar to the target image.\\nUsed transfer learning to get more accurate results.(MobileNetV2)\\nTech used : Streamlit, TensorFlow, Keras, ChromaDBProduct Search\\nTrained a custom NER model using Spacy for better accuracy in semantic search.\\nDetects and extracts filtering information regarding colour, prices and sizes.\\nUsed Flask to create the API and AJAX for faster responses.\\nTech used : Flask, AJAX, Spacy, ChromaDB, TensorFlow\\nBachelor of Technology - Computer Science and Enginnering2021 - 2025 | JSS Academy Of Technical Education, Noida\\nProgramming Languages : Python, C\\nFrameworks & Libraries : Tensorflow, Keras, Pandas, Groq, \\nUtilities : ChromaDB, SQLite, MySQLGithubWORK EXPERIENCE:\\nRELEVANT PROJECTS:\\nEDUCATION:\\nSKILLS:Github\\nSenior Secondary 2020 | R.K. Senior Secondary School, Lucknow\\nSecondary2018| Maharishi Vidya Mandir Sr. Sec. School, Fatehpur\\n93.8 %93.4 %9.07(current)\\nAWARDS:\\nRecognized for achieving the 2nd rank across all branches in the academic year 2022-23Academic Appreciation Award (2022-23)\\nRecognized for achieving the 3rd rank in Computer Science and Engineering branch in the academic year\\n2021-22.Academic Appreciation Award (2021-22)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\n",
    "reader = PdfReader(\"Harshit_ML_Resume.pdf\")\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HARSHIT SAHU\\nMachine Learning Engineer\\n+91 6393455797 | harshitsahu.sh@gmail.com | LinkedIn | Github\\nCAREER SUMMARY:\\nAspiring Machine Learning Engineer with a strong foundation in machine learning algorithms and deep\\nlearning, seeking to contribute skills and enthusiasm. Proficient in Python, TensorFlow, and Keras, with\\nacademic projects demonstrating the ability to develop and deploy machine learning models effectively.\\nWebkul\\nMachine Learning Engineer Intern |  01 July, 2024 - Present\\nCreated a RAG chatbot with memory retention using product documentation to help the customers\\nsolve their queries.\\nCreated a resume extractor application to extract the relevant details such as personal info, skillset,\\nyears of experience from a collection of CVs.\\nCreated API using Flask to store the extracted information in a database for future processing.\\nVisual Search\\nBuilt an app using Streamlit to find the images present in a dataset similar to the target image.',\n",
       " 'Created a RAG chatbot with memory retention using product documentation to help the customers\\nsolve their queries.\\nCreated a resume extractor application to extract the relevant details such as personal info, skillset,\\nyears of experience from a collection of CVs.\\nCreated API using Flask to store the extracted information in a database for future processing.\\nVisual Search\\nBuilt an app using Streamlit to find the images present in a dataset similar to the target image.\\nUsed transfer learning to get more accurate results.(MobileNetV2)\\nTech used : Streamlit, TensorFlow, Keras, ChromaDBProduct Search\\nTrained a custom NER model using Spacy for better accuracy in semantic search.\\nDetects and extracts filtering information regarding colour, prices and sizes.\\nUsed Flask to create the API and AJAX for faster responses.\\nTech used : Flask, AJAX, Spacy, ChromaDB, TensorFlow\\nBachelor of Technology - Computer Science and Enginnering2021 - 2025 | JSS Academy Of Technical Education, Noida',\n",
       " 'Tech used : Streamlit, TensorFlow, Keras, ChromaDBProduct Search\\nTrained a custom NER model using Spacy for better accuracy in semantic search.\\nDetects and extracts filtering information regarding colour, prices and sizes.\\nUsed Flask to create the API and AJAX for faster responses.\\nTech used : Flask, AJAX, Spacy, ChromaDB, TensorFlow\\nBachelor of Technology - Computer Science and Enginnering2021 - 2025 | JSS Academy Of Technical Education, Noida\\nProgramming Languages : Python, C\\nFrameworks & Libraries : Tensorflow, Keras, Pandas, Groq, \\nUtilities : ChromaDB, SQLite, MySQLGithubWORK EXPERIENCE:\\nRELEVANT PROJECTS:\\nEDUCATION:\\nSKILLS:Github\\nSenior Secondary 2020 | R.K. Senior Secondary School, Lucknow\\nSecondary2018| Maharishi Vidya Mandir Sr. Sec. School, Fatehpur\\n93.8 %93.4 %9.07(current)\\nAWARDS:\\nRecognized for achieving the 2nd rank across all branches in the academic year 2022-23Academic Appreciation Award (2022-23)',\n",
       " 'Programming Languages : Python, C\\nFrameworks & Libraries : Tensorflow, Keras, Pandas, Groq, \\nUtilities : ChromaDB, SQLite, MySQLGithubWORK EXPERIENCE:\\nRELEVANT PROJECTS:\\nEDUCATION:\\nSKILLS:Github\\nSenior Secondary 2020 | R.K. Senior Secondary School, Lucknow\\nSecondary2018| Maharishi Vidya Mandir Sr. Sec. School, Fatehpur\\n93.8 %93.4 %9.07(current)\\nAWARDS:\\nRecognized for achieving the 2nd rank across all branches in the academic year 2022-23Academic Appreciation Award (2022-23)\\nRecognized for achieving the 3rd rank in Computer Science and Engineering branch in the academic year\\n2021-22.Academic Appreciation Award (2021-22)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 500).split_text(text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/harshit.sahu/Desktop/github_pros/agentic_chatbot/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.from_texts(chunks, HuggingFaceEmbeddings())\n",
    "db.save_local(\"hs_resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/harshit.sahu/Desktop/github_pros/agentic_chatbot/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.load_local(\"hs_resume\", HuggingFaceEmbeddings(), allow_dangerous_deserialization=True)\n",
    "db_retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='HARSHIT SAHU\\nMachine Learning Engineer\\n+91 6393455797 | harshitsahu.sh@gmail.com | LinkedIn | Github\\nCAREER SUMMARY:\\nAspiring Machine Learning Engineer with a strong foundation in machine learning algorithms and deep\\nlearning, seeking to contribute skills and enthusiasm. Proficient in Python, TensorFlow, and Keras, with\\nacademic projects demonstrating the ability to develop and deploy machine learning models effectively.\\nWebkul\\nMachine Learning Engineer Intern |  01 July, 2024 - Present\\nCreated a RAG chatbot with memory retention using product documentation to help the customers\\nsolve their queries.\\nCreated a resume extractor application to extract the relevant details such as personal info, skillset,\\nyears of experience from a collection of CVs.\\nCreated API using Flask to store the extracted information in a database for future processing.\\nVisual Search\\nBuilt an app using Streamlit to find the images present in a dataset similar to the target image.'),\n",
       " Document(page_content='Programming Languages : Python, C\\nFrameworks & Libraries : Tensorflow, Keras, Pandas, Groq, \\nUtilities : ChromaDB, SQLite, MySQLGithubWORK EXPERIENCE:\\nRELEVANT PROJECTS:\\nEDUCATION:\\nSKILLS:Github\\nSenior Secondary 2020 | R.K. Senior Secondary School, Lucknow\\nSecondary2018| Maharishi Vidya Mandir Sr. Sec. School, Fatehpur\\n93.8 %93.4 %9.07(current)\\nAWARDS:\\nRecognized for achieving the 2nd rank across all branches in the academic year 2022-23Academic Appreciation Award (2022-23)\\nRecognized for achieving the 3rd rank in Computer Science and Engineering branch in the academic year\\n2021-22.Academic Appreciation Award (2021-22)'),\n",
       " Document(page_content='Created a RAG chatbot with memory retention using product documentation to help the customers\\nsolve their queries.\\nCreated a resume extractor application to extract the relevant details such as personal info, skillset,\\nyears of experience from a collection of CVs.\\nCreated API using Flask to store the extracted information in a database for future processing.\\nVisual Search\\nBuilt an app using Streamlit to find the images present in a dataset similar to the target image.\\nUsed transfer learning to get more accurate results.(MobileNetV2)\\nTech used : Streamlit, TensorFlow, Keras, ChromaDBProduct Search\\nTrained a custom NER model using Spacy for better accuracy in semantic search.\\nDetects and extracts filtering information regarding colour, prices and sizes.\\nUsed Flask to create the API and AJAX for faster responses.\\nTech used : Flask, AJAX, Spacy, ChromaDB, TensorFlow\\nBachelor of Technology - Computer Science and Enginnering2021 - 2025 | JSS Academy Of Technical Education, Noida')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_retriever.invoke(\"projects\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
